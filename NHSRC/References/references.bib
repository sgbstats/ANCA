@article{RN133,
   author = {Brix, Silke R and Noriega, Mercedes and Tennstedt, Pierre and Vettorazzi, Eik and Busch, Martin and Nitschke, Martin and Jabs, Wolfram J and Özcan, Fedai and Wendt, Ralph and Hausberg, Martin},
   title = {Development and validation of a renal risk score in ANCA-associated glomerulonephritis},
   journal = {Kidney international},
   volume = {94},
   number = {6},
   pages = {1177-1188},
   ISSN = {0085-2538},
   year = {2018},
   type = {Journal Article}
}

@article{RN250,
   author = {Bullock, Garrett S. and Mylott, Joseph and Hughes, Tom and Nicholson, Kristen F. and Riley, Richard D. and Collins, Gary S.},
   title = {Just How Confident Can We Be in Predicting Sports Injuries? A Systematic Review of the Methodological Conduct and Performance of Existing Musculoskeletal Injury Prediction Models in Sport},
   journal = {Sports medicine (Auckland)},
   volume = {52},
   number = {10},
   pages = {2469-2482},
   abstract = {Background An increasing number of musculoskeletal injury prediction models are being developed and implemented in sports medicine. Prediction model quality needs to be evaluated so clinicians can be informed of their potential usefulness. Objective To evaluate the methodological conduct and completeness of reporting of musculoskeletal injury prediction models in sport. Methods A systematic review was performed from inception to June 2021. Studies were included if they: (1) predicted sport injury; (2) used regression, machine learning, or deep learning models; (3) were written in English; (4) were peer reviewed. Results Thirty studies (204 models) were included; 60% of studies utilized only regression methods, 13% only machine learning, and 27% both regression and machine learning approaches. All studies developed a prediction model and no studies externally validated a prediction model. Two percent of models (7% of studies) were low risk of bias and 98% of models (93% of studies) were high or unclear risk of bias. Three studies (10%) performed an a priori sample size calculation; 14 (47%) performed internal validation. Nineteen studies (63%) reported discrimination and two (7%) reported calibration. Four studies (13%) reported model equations for statistical predictions and no machine learning studies reported code or hyperparameters. Conclusion Existing sport musculoskeletal injury prediction models were poorly developed and have a high risk of bias. No models could be recommended for use in practice. The majority of models were developed with small sample sizes, had inadequate assessment of model performance, and were poorly reported. To create clinically useful sports musculoskeletal injury prediction models, considerable improvements in methodology and reporting are urgently required.},
   keywords = {Bias
Deep learning
Learning algorithms
Machine learning
Mathematical models
Medicine
Medicine & Public Health
Open access
Prediction models
Regression analysis
Sports injuries
Sports Medicine
Systematic Review},
   ISSN = {0112-1642},
   DOI = {10.1007/s40279-022-01698-9},
   year = {2022},
   type = {Journal Article}
}

@article{RN247,
   author = {Canturk, Toros C. and Czikk, Daniel and Wai, Eugene K. and Phan, Philippe and Stratton, Alexandra and Michalowski, Wojtek and Kingwell, Stephen},
   title = {A scoping review of complication prediction models in spinal surgery: An analysis of model development, validation and impact},
   journal = {North American Spine Society Journal},
   volume = {11},
   pages = {100142-100142},
   abstract = {Predictive analytics are being used increasingly in the field of spinal surgery with the development of models to predict post-surgical complications. Predictive models should be valid, generalizable, and clinically useful. The purpose of this review was to identify existing post-surgical complication prediction models for spinal surgery and to determine if these models are being adequately investigated with internal/external validation, model updating and model impact studies. This was a scoping review of studies pertaining to models for the prediction of post-surgical complication after spinal surgery published over 10 years (2010-2020). Qualitative data was extracted from the studies to include study classification, adherence to Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) guidelines and risk of bias (ROB) assessment using the Prediction model study Risk Of Bias Assessment Tool (PROBAST). Model evaluation was determined using area under the curve (AUC) when available. The Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) statement was used as a basis for the search methodology in four different databases. Thirty studies were included in the scoping review and 80% (24/30) included model development with or without internal validation. Twenty percent (6/30) were exclusively external validation studies and only one study included an impact analysis in addition to model development and internal validation. Two studies referenced the TRIPOD guidelines and there was a high ROB in 100% of the studies using the PROBAST tool. The majority of post-surgical complication prediction models in spinal surgery have not undergone standardized model development and internal validation or adequate external validation and impact evaluation. As such there is uncertainty as to their validity, generalizability, and clinical utility. Future efforts should be made to use existing tools to ensure standardization in development and rigorous evaluation of prediction models in spinal surgery.},
   keywords = {model development
model validation
orthopedic procedures
Postoperative complications
Prediction model
Scoping review
Spinal surgery},
   ISSN = {2666-5484},
   DOI = {10.1016/j.xnsj.2022.100142},
   year = {2022},
   type = {Journal Article}
}

@article{RN251,
   author = {Carr, Bethany L. and Jahangirifar, Maryam and Nicholson, Ann E. and Li, Wentao and Mol, Ben W. and Licqurish, Sharon},
   title = {Predicting postpartum haemorrhage: A systematic review of prognostic models},
   journal = {Australian & New Zealand journal of obstetrics & gynaecology},
   abstract = {BACKGROUNDPostpartum haemorrhage (PPH) remains a leading cause of maternal mortality and morbidity worldwide, and the rate is increasing. Using a reliable predictive model could identify those at risk, support management and treatment, and improve maternal outcomes. AIMSTo systematically identify and appraise existing prognostic models for PPH and ascertain suitability for clinical use. MATERIALS AND METHODSMEDLINE, CINAHL, Embase, and the Cochrane Library were searched using combinations of terms and synonyms, including 'postpartum haemorrhage', 'prognostic model', and 'risk factors'. Observational or experimental studies describing a prognostic model for risk of PPH, published in English, were included. The Critical Appraisal and Data Extraction for Systematic Reviews of Prediction Modelling Studies checklist informed data extraction and the Prediction Model Risk of Bias Assessment Tool guided analysis. RESULTSSixteen studies met the inclusion criteria after screening 1612 records. All studies were hospital settings from eight different countries. Models were developed for women who experienced vaginal birth (n = 7), caesarean birth (n = 2), any type of birth (n = 2), hypertensive disorders (n = 1) and those with placental abnormalities (n = 4). All studies were at high risk of bias due to use of inappropriate analysis methods or omission of important statistical considerations or suboptimal validation. CONCLUSIONSNo existing prognostic models for PPH are ready for clinical application. Future research is needed to externally validate existing models and potentially develop a new model that is reliable and applicable to clinical practice.},
   ISSN = {1479-828X},
   DOI = {10.1111/ajo.13599},
   year = {2022},
   type = {Journal Article}
}

@misc{RN252,
   author = {Collins, Gary S},
   title = {I've also recently been updating my list   @MaartenvSmeden   (for a talk). Below are ~260 systematic reviews of clinical prediction models - you might've missed a couple  - it's incomplete, and probably has some inaccuracies (still updating it).

  #modelmania},
   number = {4/10/2022},
   url = {https://twitter.com/GSCollins/status/1506249323180437507},
   year = {2022},
   type = {Web Page},
   urldate = {2022-10-05}
}

@article{RN132,
   author = {Collins, Gary S and Reitsma, Johannes B and Altman, Douglas G and Moons, Karel GM},
   title = {Transparent reporting of a multivariable prediction model for individual prognosis or diagnosis (TRIPOD): the TRIPOD statement},
   journal = {Journal of British Surgery},
   volume = {102},
   number = {3},
   pages = {148-158},
   ISSN = {0007-1323},
   year = {2015},
   type = {Journal Article}
}

@article{RN248,
   author = {Dhiman, Paula and Ma, Jie and Andaur Navarro, Constanza L. and Speich, Benjamin and Bullock, Garrett and Damen, Johanna A. A. and Hooft, Lotty and Kirtley, Shona and Riley, Richard D. and Van Calster, Ben and Moons, Karel G. M. and Collins, Gary S.},
   title = {Risk of bias of prognostic models developed using machine learning: a systematic review in oncology},
   journal = {Diagnostic and prognostic research},
   volume = {6},
   number = {1},
   pages = {13-13},
   abstract = {BACKGROUNDPrognostic models are used widely in the oncology domain to guide medical decision-making. Little is known about the risk of bias of prognostic models developed using machine learning and the barriers to their clinical uptake in the oncology domain. METHODSWe conducted a systematic review and searched MEDLINE and EMBASE databases for oncology-related studies developing a prognostic model using machine learning methods published between 01/01/2019 and 05/09/2019. The primary outcome was risk of bias, judged using the Prediction model Risk Of Bias ASsessment Tool (PROBAST). We described risk of bias overall and for each domain, by development and validation analyses separately. RESULTSWe included 62 publications (48 development-only; 14 development with validation). 152 models were developed across all publications and 37 models were validated. 84% (95% CI: 77 to 89) of developed models and 51% (95% CI: 35 to 67) of validated models were at overall high risk of bias. Bias introduced in the analysis was the largest contributor to the overall risk of bias judgement for model development and validation. 123 (81%, 95% CI: 73.8 to 86.4) developed models and 19 (51%, 95% CI: 35.1 to 67.3) validated models were at high risk of bias due to their analysis, mostly due to shortcomings in the analysis including insufficient sample size and split-sample internal validation. CONCLUSIONSThe quality of machine learning based prognostic models in the oncology domain is poor and most models have a high risk of bias, contraindicating their use in clinical practice. Adherence to better standards is urgently needed, with a focus on sample size estimation and analysis methods, to improve the quality of these models.},
   keywords = {Machine learning
Prediction modelling
Risk of bias
Systematic review},
   ISSN = {2397-7523},
   DOI = {10.1186/s41512-022-00126-w},
   year = {2022},
   type = {Journal Article}
}

@article{RN131,
   author = {Moons, Karel GM and Altman, Douglas G and Reitsma, Johannes B and Ioannidis, John PA and Macaskill, Petra and Steyerberg, Ewout W and Vickers, Andrew J and Ransohoff, David F and Collins, Gary S},
   title = {Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD): explanation and elaboration},
   journal = {Annals of internal medicine},
   volume = {162},
   number = {1},
   pages = {W1-W73},
   ISSN = {0003-4819},
   year = {2015},
   type = {Journal Article}
}

@article{RN245,
   author = {van Royen, Florien S. and Moons, Karel G.M. and Geersing, Geert-Jan and van Smeden, Maarten},
   title = {Developing, validating, updating and judging the impact of prognostic models for respiratory diseases},
   journal = {European Respiratory Journal},
   pages = {2200250},
   DOI = {10.1183/13993003.00250-2022},
   url = {https://erj.ersjournals.com/content/erj/early/2022/05/26/13993003.00250-2022.full.pdf},
   year = {2022},
   type = {Journal Article}
}

@article{RN253,
   author = {Pearce, Fiona A. and Lanyon, Peter C. and Grainge, Matthew J. and Shaunak, Reena and Mahr, Alfred and Hubbard, Richard B. and Watts, Richard A.},
   title = {Incidence of ANCA-associated vasculitis in a UK mixed ethnicity population},
   journal = {Rheumatology.},
   volume = {55},
   number = {9},
   pages = {1656-1663},
   ISSN = {1462-0324},
   DOI = {10.1093/rheumatology/kew232},
   year = {2016},
   type = {Journal Article}
}

@article{RN138,
   author = {Royston, Patrick and Altman, Douglas G},
   title = {External validation of a Cox prognostic model: principles and methods},
   journal = {BMC medical research methodology},
   volume = {13},
   number = {1},
   pages = {1-15},
   ISSN = {1471-2288},
   year = {2013},
   type = {Journal Article}
}

@article{RN249,
   author = {Sarrió‐Sanz, Pau and Martinez‐Cayuelas, Laura and Lumbreras, Blanca and Sánchez‐Caballero, Laura and Palazón‐Bru, Antonio and Gil‐Guillén, Vicente F. and Gómez‐Pérez, Luis},
   title = {Mortality prediction models after radical cystectomy for bladder tumour: A systematic review and critical appraisal},
   journal = {European journal of clinical investigation},
   volume = {52},
   number = {10},
   pages = {e13822-n/a},
   note = {Funding information},
   abstract = {Introduction To identify risk‐predictive models for bladder‐specific cancer mortality in patients undergoing radical cystectomy and assess their clinical utility and risk of bias. Methods Systematic review (CRD42021224626:PROSPERO) in Medline and EMBASE (from their creation until 31/10/2021) was screened to include articles focused on the development and internal validation of a predictive model of specific cancer mortality in patients undergoing radical cystectomy. CHecklist for critical Appraisal and data extraction for systematic Reviews of prediction Modelling Studies (CHARMS) and Prediction model Risk Of Bias ASsessment Tool (PROBAST) were applied. Results Nineteen observational studies were included. The main predictors were sociodemographic variables, such as age (18 studies, 94.7%) and sex (17, 89.5% studies), tumour characteristics (TNM stage (18 studies, 94.7%), histological subtype/grade (15 studies, 78.9%), lymphovascular invasion (10 studies, 52.6%) and treatment with chemotherapy (13 studies, 68.4%). C‐index values were presented in 14 studies. The overall risk of bias assessed using PROBAST led to 100% of studies being classified as high risk (the analysis domain was rated to be at high risk of bias in all the studies), and 52.6% showed low applicability. Only 5 studies (26.3%) included an external validation and 2 (10.5%) included a prospective study design. Conclusions Using clinical predictors to assess the risk of bladder‐specific cancer mortality is a feasibility alternative. However, the studies showed a high risk of bias and their applicability is uncertain. Studies should improve the conducting and reporting, and subsequent external validation studies should be developed.},
   keywords = {Analysis
Bias
Bladder
Cancer
Chemotherapy
Content analysis
Feasibility studies
Health aspects
Literature reviews
Mortality
nomograms
Oncology, Experimental
Patients
Prediction models
radical cystectomy
Risk analysis
Risk assessment
Systematic review
Tumors
urinary bladder neoplasms},
   ISSN = {0014-2972},
   DOI = {10.1111/eci.13822},
   year = {2022},
   type = {Journal Article}
}



